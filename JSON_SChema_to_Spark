import json
from pyspark.sql import SparkSession
from pyspark.sql.types import (
    StructType, StructField, StringType, LongType, ArrayType, MapType, DoubleType, BooleanType
)

# Function to read JSON schema from a file
def read_json_schema(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)

# Function to convert JSON schema to PySpark schema
def convert_json_schema_to_pyspark(schema_dict):
    fields = schema_dict['fields']
    spark_fields = []
    
    for field in fields:
        field_name = field['name']
        field_type = field['type']
        nullable = field['nullable']
        
        if field_type == 'string':
            spark_field_type = StringType()
        elif field_type == 'long':
            spark_field_type = LongType()
        elif field_type == 'double':
            spark_field_type = DoubleType()
        elif field_type == 'boolean':
            spark_field_type = BooleanType()
        elif field_type == 'array':
            element_type = field['elementType']
            spark_field_type = ArrayType(convert_json_to_spark_type(element_type), containsNull=nullable)
        elif field_type == 'map':
            key_type = field['keyType']
            value_type = field['valueType']
            spark_field_type = MapType(convert_json_to_spark_type(key_type), convert_json_to_spark_type(value_type), valueContainsNull=nullable)
        elif field_type == 'struct':
            spark_field_type = convert_json_schema_to_pyspark(field)  # Recursive call for struct
        else:
            raise ValueError(f"Unsupported field type: {field_type}")
        
        spark_fields.append(StructField(field_name, spark_field_type, nullable))
    
    return StructType(spark_fields)

def convert_json_to_spark_type(data_type):
    """Convert simple data types to Spark types."""
    if data_type == 'string':
        return StringType()
    elif data_type == 'long':
        return LongType()
    elif data_type == 'double':
        return DoubleType()
    elif data_type == 'boolean':
        return BooleanType()
    else:
        raise ValueError(f"Unsupported data type: {data_type}")

# Create a Spark session
spark = SparkSession.builder \
    .appName("JSON to PySpark Schema") \
    .getOrCreate()

# Read schema from external JSON file
schema_dict = read_json_schema('schema.json')

# Convert and print the PySpark schema
pyspark_schema = convert_json_schema_to_pyspark(schema_dict)
print(pyspark_schema)

# Stop the Spark session
spark.stop()
